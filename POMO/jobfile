#!/bin/bash
# FILENAME:  jobfile
#SBATCH -A cis240074-gpu      # allocation name
#SBATCH --nodes=1             # Total # of nodes
#SBATCH --ntasks-per-node=1   # Number of MPI ranks per node (one rank per GPU)
#SBATCH --gpus-per-node=1     # Number of GPUs per node
#SBATCH --cpus-per-task=1    # cpu-cores per task (default value is 1, >1 for multi-threaded tasks)
#SBATCH --time=1:00:00        # Total run time limit (hh:mm:ss)
#SBATCH -J rackmovement       # Job name
#SBATCH -o leader_reward.o%j   # Name of stdout output file
#SBATCH -e leader_reward.e%j   # Name of stderr error file
#SBATCH -p gpu                # Queue (partition) name
#SBATCH --mail-user=chen3365@purdue.edu
#SBATCH --mail-type=all       # Send email to above address at begin and end of job
cd $SLURM_SUBMIT_DIR
module purge
module load modtree/gpu
module list
module load anaconda
conda activate gdm
python train_n10.py 
